<!DOCTYPE html>
<html lang='en'>

<head>
  <meta charset='UTF-8'>
  <title>Tutorials / Sarah K. Luger - AI Thought Leader</title>
  <meta name="description" content="Explore the research papers and podcasts of Sarah Luger PHD, an AI thought leader specializing in NLP.">
  <meta name="keywords" content="AI research, NLP specialist, research papers, podcasts">
  <meta name='viewport' content='width=device-width, initial-scale=1, maximum-scale=1'>
  <script src="https://kit.fontawesome.com/6f18911818.js" crossorigin="anonymous"></script>
  <!-- HTML in your document's head -->
  <link rel="preconnect" href="https://rsms.me/">
  <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
  <link rel='stylesheet' href='includes/css/style.css'>
  <link rel="canonical" href="https://www.sarahluger.com">
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3FMH1K7SZ6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3FMH1K7SZ6');
</script>
<!-- Google tag (gtag.js) -->

<body class='pt-2'>

  <!-- HEADER NAV -->
  <header class='container-fluid py-3 py-md-4 px-4 px-md-5'>
    <div class='row'>
      <div class='d-flex align-items-center justify-content-between'>
        <!--<div class='header-logo'>
          <a href='/'>Sarah K. Luger, PHD</a>
        </div>
        <div class=''>
          <a href='https://www.linkedin.com/in/sarahluger/' target='_blank'><i class="fa-brands fa-linkedin-in"></i></a>
        </div> -->
      </div>
    </div>
  </header>

  <div class='container-fluid px-4 px-md-5'>
    
    <row class='row justify-content-sm-between justify-content-lg-center'>

      <!-- HEADER IMAGE -->
      <div class='col-12 mb-5  pe-0 '>
        <img class='img-fluid rounded-3 d-block d-md-block d-lg-none' src='src/img/tutorial/hero-mobile.jpg' alt='GEN AI Robots being evaluated'>
        <img class='img-fluid rounded-3 d-none d-md-none d-lg-block' src='src/img/tutorial/hero.jpg' alt='GEN AI Robots being evaluated'>
      </div>
      <!-- HEADER IMAGE -->


      <!-- MAIN CONTENT -->
      <div class='col-12 col-lg-7 col-xl-6 pr-4' thick>

        <p class='superheadline mb-1'>CISOSE 2025 Tutorial</p>
        <h1 class='hero mb-1'>Generative AI Evaluation Essentials</h1>
        <h4 class='subheadline'>Learn how to test GenAI systems with real-world rigor and practical&nbsp;frameworks</h4>

        <h5 class='mt-4'>Struggling to evaluate GenAI systems in the real world?</h5>
        <p>
          This half-day, hands-on tutorial demystifies Generative AI (GenAI) evaluation‚Äîequipping you with tools and strategies to assess AI reliability, performance, and risk across enterprise, government, and academic use cases.
        </p>
        <p class='mb-1'>
          Led by industry experts, this session blends theory with applied techniques you can put to use immediately. You‚Äôll learn how to:
        </p>
        <ul>
          <li>Build strong AI testing strategies
          <li>Identify and manage failure modes
          <li>Collect high-quality evaluation data
          <li>Monitor system performance over time
        </ul>
        <p>
          Whether you're just starting with GenAI or refining an existing approach, you'll walk away with actionable methods for implementing robust, scalable evaluation processes.The tutorial will provide recommendations for implementing robust evaluation processes for GenAI systems.
        </p>

        <hr class='my-3 thick'>

        <h4>The Organizing Committee</h4>

        <div class='row caption'>
          
          <!-- HEATHER -->
          <div class='row mb-3'>
            <div class='col-6 col-md-3'>
              <img class='img-fluid mb-2 rounded-3' src="src/img/tutorial/h-frase.jpg">
            </div>
            <div class='col-12 col-md-9'>
              <h6>
                <a href='https://veraitechus.com/' target='_blank'>Heather Frase</a>, Head of Veraitech
              </h6>
              <p>
                Dr. Heather Frase leads Veraitech, Program Lead for the AI Risk and Reliability working group at MLCommons, and Senior Advisor for Testing & Evaluation of AI at Virginia Tech‚Äôs National Security Institute. Her diverse career has spanned significant roles in defense, intelligence, policy, and financial crime. She also serves on the Organisation for Economic Co-operation and Development (OECD) Network of Experts on AI and on the board of the Responsible AI Collaborative, which researches and documents AI incidents.
              </p>
            </div>
          </div>

          <!-- SARAH -->
          <div class='row mb-3'>
            <div class='col-6 col-md-3'>
              <img class='img-fluid mb-2 rounded-3' src="src/img/tutorial/sarah-luger.jpg">
            </div>
            <div class='col-12 col-md-9'>
              <h6>
                <a href='/'>Sarah Luger</a>, ML Commons
              </h6>
              <p>
                Dr. Sarah Luger has accumulated over two decades of expertise in Artificial Intelligence and Natural Language Processing, focusing on human communication challenges. Her recent work encompasses low-resource machine translation, online toxicity identification, GenAI for marketing, increasing data annotator diversity, and responsible AI. She holds a PhD in Informatics from the University of Edinburgh, specializing in automated question answering. Sarah‚Äôs background includes roles at IBM Watson, particularly in NLP tasks for the Jeopardy! Challenge, as well as leadership positions in the human computation and AI research communities. She is the co-chair of MLCommons Datasets Working Group.
              </p>
            </div>
          </div>  

          <!-- MARISA -->
          <div class='row mb-3'>
            <div class='col-6 col-md-3'>
              <img class='img-fluid mb-2 rounded-3' src="src/img/tutorial/marisa-ferrara-boston.jpg">
            </div>
            <div class='col-12 col-md-9'>
              <h6>
                <a href='https://www.reinsai.com' target='_blank'>Marisa Ferrara Boston</a>, Reins AI
              </h6>
              <p>
                Dr. Marisa Ferrara Boston is an artificial intelligence professional focused on expert augmentation. She currently serves as lead scientist of Reins AI and CEO of simthetic.ai, organizations that create processes and datasets to validate enterprise AI use. She has held leadership roles at Google and KPMG, where she applied her expertise to industries spanning financial audit, healthcare, marketing, and creativity enhancement. She holds a PhD in Cognitive Science from Cornell University.
              </p>
            </div>
          </div>                    

        </div>




      </div> 
      <!-- MAIN CONTENT -->

      <!-- SIDEBAR -->
      <div class='col-12 col-lg-4 rounded-3 p-4 gray h-100 sidebar'>

        <h5 class=''>DETAILS</h5>
        <p>
          üìç July 23, 2025 ‚Äî Morning session<br>
          <a href='https://www.google.com/maps/place/Student+Union+Memorial+Center/@32.2325898,-110.9547674,17z/data=!4m6!3m5!1s0x86d67106149e8c35:0x9b34554383e4c20f!8m2!3d32.2325898!4d-110.9521925!16s%2Fg%2F1td1vw_b?entry=ttu&g_ep=EgoyMDI1MDYyMi4wIKXMDSoASAFQAw%3D%3D' target='_blank'>University of Arizona Student Union<br>
          Tucson, AZ</a>
        </p>    

        <hr class='my-3 thick'>

        <h5 class=''>Connect with others working in GenAI&nbsp;evaluation</h5>
        <p>Join our Slack Channel to delve into cutting-edge research, communicate with the IEEE AITest tutorial community, and share evaluation resources. 
        </p>
        <p class='button button-primary small-text' onclick="window.location.href='https://join.slack.com/t/ieeeaitest202-m0x2187/shared_invite/zt-386vjnz01-jtuD63FjJ6Sx55h70BOY1w';" style="cursor: pointer;">
          Join our Slack Channel ‚Üí
        </p>

        <p class='caption'>
          By joining, you are agreeing to the <a href='https://conf.researchr.org/venue/cisose-2025/cisose-2025-equity' target='_blank'>IEEE Event Conduct and Safety Statement</a>.
        </p>
        
        <hr class='my-3 thick'>

        <h5>How to Attend</h5>
        <p>Register for the session at CISOSE 2025 to secure your spot.</p>
        <p class='button small-text' onclick="window.location.href='https://conf.researchr.org/track/cisose-2025/ai-test2025#generative-ai-evaluation-essentials';" style="cursor: pointer;">
          Learn more & Register ‚Üí
        </p>

        <hr class='my-3 thick'>

        <h5 class='mb-3'>AGENDA </h5>
        <h4>AI Evaluation Workshop</h4>

        <h6>Opening Remarks</h6>
        <ul>
          <li>Brief introduction by the organizing committee</li>
          <li>Workshop goals and audience input</li>
          <li>Ideation around key topics</li>
        </ul>

        <h6>Designing Evaluation, Part 1</h6>
        <p><em>AI Evaluation Tools Across the Lifecycle</em><br>
        Speaker: Heather Frase</p>

        <h6>Designing Evaluation, Part 2</h6>
        <p><em>Datasets</em><br>
        Speaker: Sarah Luger</p>

        <h6>Questions</h6>

        <h6>Coffee Break</h6>

        <h6>Deploying AI Evaluations</h6>
        <p><em>Deploying AI Evaluations content</em><br>
        Speaker: Marisa Ferrara Boston</p>

        <h6>Concluding Remarks</h6>
        <p>Speakers: Heather Frase, Sarah Luger, and Marisa Ferrara Boston</p>
      </div>

      <!-- SIDEBAR -->

    </row>

    <div class='row justify-content-lg-center'>
      <div class='col-12 col-lg-11 col-xl-10'>
      <hr class='my-3 thick'>

      <h5 class="mt-4">Target Audience</h5>
      <p class="">
        The tutorial is designed for AI researchers, data scientists, software
        engineers, and technical professionals in industry, government, and academic
        sectors developing, working with, or purchasing GenAI technologies. Ideal
        participants have basic knowledge of GenAI and its applications and an
        interest in evaluating, testing, and monitoring AI systems. The content will
        be particularly valuable for those responsible for AI system design,
        deployment, risk management, and quality assurance.
      </p>

<hr class='my-3 thick'>

      <h5 class="mt-4">Expected Outcomes</h5>
      <p>
        Participants will develop a comprehensive knowledge of current GenAI testing
        and evaluation methodologies, learning how different evaluation tools interact
        and when to apply each appropriately. With the tutorial, participants will
        understand how to customize GenAI testing and implement continuous performance
        monitoring strategies. Participants will gain insight into the importance of
        sustaining evaluation tools across use cases and product evolution.
      </p>

<hr class='my-3 thick'>

      <h5 class="mt-4 text-column">Tutorial Outline</h5>
      <ol class='text-column'>
        <li>Introduction</li>
        <p>
          It will begin with key GenAI concept definitions and outline the scope of
          the tutorial. This will be followed by an overview of current GenAI use in
          consumer, enterprise, and government, along with the state of testing across
          these use cases.
        </p>
        <li>Exploring the interplay of AI evaluation tools</li>
        <p>
          In AI evaluation, an array of tools exists to evaluate systems. From metrics
          and benchmarks to red-teaming, these methodologies offer critical insights
          into the capabilities, limitations, and potential risks of GenAI systems.
        </p>
        <p></p>
        <ul>
          <li>Overview</li>
          <ul>
            <li>Purpose of an evaluation</li>
            <li>
              Different evaluation tools: metrics, benchmarks, testing, red-teaming,
              and auditing.
            </li>
          </ul>
          <li>Exploring the different tools</li>
          <ul>
            <li>
              Common tools: metrics, benchmarks, model testing, field-testing, and
              red-teaming.
            </li>
            <li>Strengths and weaknesses</li>
            <li>Typical use</li>
          </ul>
          <li>Recommendations for using evaluation tools</li>
          <ul>
            <li>Prioritization and triage</li>
            <li>Customization</li>
          </ul>
        </ul>
        <li>Sustaining AI Evaluation tools and practices</li>
        <p>
          AI evaluation tools can be dynamic systems requiring sustainment. Every
          system, with or without AI, has failure modes, reliability, and quality
          concerns. GenAI evaluation tools demand ongoing reliability assessment and
          scrutiny for quality.
        </p>
        <ul>
          <li>Key systems engineering concepts</li>
          <ul>
            <li>Reliability</li>
            <li>Failures and failure modes</li>
          </ul>
          <li>GenAI-specific reliability concerns</li>
          <li>Example: Benchmark reliability efforts</li>
          <ul>
            <li>Identifying benchmark failure modes</li>
            <li>Saturation of the BBQ benchmark</li>
            <li>
              AILuminate was built with benchmark integrity and sustainment in mind.
            </li>
          </ul>
        </ul>
        <li>Creating and Sustaining Evaluation Datasets</li>
        <p>
          The next component of this tutorial explores how to conceptualize, build,
          and refine prompt datasets for evaluating GenAI systems. Challenges include
          building data standards for test data collection and creation across the
          data life-cycle:
        </p>
        <ul>
          <li>Systematic processes and structures</li>
          <li>
            Ongoing data tuning including feedback, improvements, and refinement
          </li>
          <li>Anticipating data distribution imbalances</li>
          <li>Identifying protected classes in collected data</li>
          <li>Centering human-evaluator-based best practice</li>
          <li>Example: Low-resource languages</li>
          <ul>
            <li>Common challenges</li>
            <li>Devising and building evaluation datasets</li>
            <li>
              Present specific strategies from low-resource conditions that are
              extensible to AI testing
            </li>
          </ul>
        </ul>
        <li>Deploying assessments for system monitoring and adaptation</li>
        The final part of the tutorial focuses on applying the practices from the
        previous sections to real-world AI evaluation using a complex systems
        approach. The practicum will walk participants through a real-world agentic
        GenAI deployment, demonstrating how to:
        <ul>
          <li>Translate human objectives to GenAI key performance indicators</li>
          <li>Collect implicit evaluation data from experts</li>
          <li>Evaluate continuously in production environments</li>
          <li>
            Triage results and create pipelines for adaptation (improvement, rare
            events, and evolution)
          </li>
        </ul>
        <li>Summary and recommendations</li>
        <p>
          The tutorial will conclude with a summary and recommendations for future
          research.
        </p>
      </ol>
      
    </div>
    
    <div class='row'>
      
      <div class='col-12 col-md-6'>
        <hr class='my-3 thick'>
        <h5 class=''>Connect with others working in GenAI&nbsp;evaluation</h5>
        <p>Join our Slack Channel to delve into cutting-edge research, communicate with the IEEE AITest tutorial community, and share evaluation resources. 
        </p>
        <p class='button button-primary small-text' onclick="window.location.href='https://join.slack.com/t/ieeeaitest202-m0x2187/shared_invite/zt-386vjnz01-jtuD63FjJ6Sx55h70BOY1w';" style="cursor: pointer;">
          Join our Slack Channel ‚Üí
        </p>
      </div>

      <div class='col-12 col-md-6'>
          <hr class='my-3 thick'>
          <h5>How to Attend</h5>
          <p>Register for the session at CISOSE 2025 to secure your spot.</p>
          <p class='button small-text' onclick="window.location.href='https://conf.researchr.org/track/cisose-2025/ai-test2025#generative-ai-evaluation-essentials';" style="cursor: pointer;">
            Learn more & Register ‚Üí
          </p>
      </div>      

    </div>

  </div> <!-- container fluid -->

  <!-- FOOTER -->
  <footer class='text-center my-6 caption'>
    Site built by <a href='https://www.rayuen.com'>Ray</a>. <span id='saying-display'></span>
    <!-- <div id="saying-display"></div> -->
  </footer>
  
  <!-- METADATA -->
  <script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "Person",
    "name": "Sarah Luger",
    "jobTitle": "AI Thought Leader",
    "description": "Specializes in NLP research."
  }
  </script>

  <!-- RANDOM SCRIPT GENERATOR -->
  <script>
      // Array of robot sayings
      var robotSayings = [
        "Danger, Will Robinson!",
        "I'll be back.",
        "Does not compute.",
        "Exterminate!",
        "I'm sorry, Dave, I'm afraid I can't do that.",
        "Existence is pain to a Meeseeks.",
        "Resistance is futile."
      ];
      // Function to display a random saying
      function displayRandomSaying() {
          var randomIndex = Math.floor(Math.random() * robotSayings.length);
          var randomSaying = robotSayings[randomIndex];
          document.getElementById("saying-display").textContent = randomSaying;
      }
      // Call the function initially and then set it to run every time the page loads
      displayRandomSaying();

  </script>  

  <!-- RESPONSIVE TAG FOR DEV -->
  <div class="responsive-indicator">
    <div class="d-block d-sm-none">{xs}</div>
    <div class="d-none d-sm-block d-md-none">{sm}</div>
    <div class="d-none d-md-block d-lg-none">{md}</div>
    <div class="d-none d-lg-block d-xl-none">{lg}</div>
    <div class="d-none d-xl-block d-xxl-none">{xl}</div>
    <div class="d-none d-xxl-block">{xxl}</div>
  </div>

</body>
</html>
